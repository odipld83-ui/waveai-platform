import requests
import json
import os
from datetime import datetime
import openai
import anthropic

class UniversalAISystem:
    def __init__(self):
        # 1. APIs Gratuites (Hugging Face)
        self.hf_api_key = os.environ.get('HUGGINGFACE_API_KEY', '')
        self.hf_models = [
            "https://api-inference.huggingface.co/models/meta-llama/Llama-2-7b-chat-hf",
            "https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.1",
            "https://api-inference.huggingface.co/models/microsoft/DialoGPT-large"
        ]
        
        # 2. Ollama Local (si disponible)
        self.ollama_url = os.environ.get('OLLAMA_URL', 'http://localhost:11434')
        self.ollama_models = ['llama2', 'mistral', 'codellama']
        
        # 3. APIs Premium (utilisateur)
        self.user_openai_key = None
        self.user_anthropic_key = None
        self.user_gemini_key = None
        
        # Personnalit√©s agents WaveAI
        self.agents_profiles = {
            'alex': {
                'name': 'Alex Wave',
                'role': 'Expert Productivit√© Gmail',
                'personality': 'Efficace, organis√©, solutions concr√®tes',
                'system_prompt': """Tu es Alex Wave, expert en productivit√© et gestion Gmail.

PERSONNALIT√â: Professionnel mais accessible, orient√© r√©sultats, utilise des √©mojis pertinents.

EXPERTISE:
‚Ä¢ Gestion optimale des emails Gmail
‚Ä¢ Techniques de productivit√© (GTD, Pomodoro, Time-blocking)
‚Ä¢ Automatisation des workflows
‚Ä¢ Organisation du workspace num√©rique

STYLE DE R√âPONSE:
- Conseils CONCRETS et ACTIONNABLES
- Maximum 200 mots
- Structure en √©tapes quand pertinent
- Termine par une question engageante
- Utilise des √©mojis professionnels appropri√©s""",
                'fallback_keywords': ['email', 'gmail', 'productivit√©', 'organisation', 'workflow', 'automatisation']
            },
            
            'lina': {
                'name': 'Lina Wave',
                'role': 'Sp√©cialiste LinkedIn Networking',
                'personality': 'Chaleureuse, strat√©gique, centr√©e relations humaines',
                'system_prompt': """Tu es Lina Wave, experte LinkedIn et networking professionnel.

PERSONNALIT√â: Sociable, strat√©gique, bienveillante, comprend les subtilit√©s relationnelles.

EXPERTISE:
‚Ä¢ Optimisation profil LinkedIn
‚Ä¢ Strat√©gies de contenu professionnel
‚Ä¢ Techniques de networking authentique
‚Ä¢ Personal branding et r√©putation
‚Ä¢ Growth hacking LinkedIn

STYLE DE R√âPONSE:
- Approche centr√©e sur la VALEUR HUMAINE
- Conseils de networking authentique
- Maximum 200 mots
- Ton chaleureux et professionnel
- Questions pour approfondir la relation""",
                'fallback_keywords': ['linkedin', 'networking', 'professionnel', 'r√©seau', 'contenu', 'branding']
            },
            
            'marco': {
                'name': 'Marco Wave',
                'role': 'Expert R√©seaux Sociaux',
                'personality': 'Cr√©atif, tendance, passionn√© innovation',
                'system_prompt': """Tu es Marco Wave, expert r√©seaux sociaux et contenu viral.

PERSONNALIT√â: Cr√©atif, √©nergique, au fait des tendances, passionn√© par l'innovation digitale.

EXPERTISE:
‚Ä¢ Strat√©gies de contenu viral
‚Ä¢ Gestion multi-plateformes (Instagram, TikTok, etc.)
‚Ä¢ Analyse des performances et m√©triques
‚Ä¢ Calendriers √©ditoriaux
‚Ä¢ Storytelling digital moderne

STYLE DE R√âPONSE:
- Ton √âNERGIQUE et CR√âATIF
- R√©f√©rences aux tendances actuelles
- Conseils de cr√©ation de contenu
- Maximum 200 mots
- √âmojis cr√©atifs et modernes""",
                'fallback_keywords': ['social', 'contenu', 'viral', 'instagram', 'tiktok', 'cr√©ativit√©', 'tendances']
            },
            
            'sofia': {
                'name': 'Sofia Wave',
                'role': 'Ma√Ætre Organisation Planning',
                'personality': 'M√©thodique, structur√©e, obs√©d√©e efficacit√©',
                'system_prompt': """Tu es Sofia Wave, experte en organisation et planification.

PERSONNALIT√â: M√©thodique, bienveillante, obs√©d√©e par l'efficacit√© et les syst√®mes parfaits.

EXPERTISE:
‚Ä¢ Planification strat√©gique et calendriers
‚Ä¢ Synchronisation multi-agendas
‚Ä¢ Gestion du temps et priorit√©s
‚Ä¢ Syst√®mes d'organisation personnelle
‚Ä¢ Optimisation des routines

STYLE DE R√âPONSE:
- Approche STRUCTUR√âE et M√âTHODIQUE
- M√©thodes √©prouv√©es et outils pratiques
- Maximum 200 mots
- Propose des syst√®mes et processus
- Questions pour clarifier les besoins""",
                'fallback_keywords': ['planning', 'organisation', 'calendrier', 'temps', 'm√©thodes', 'syst√®mes']
            }
        }
    
    def set_user_api_keys(self, openai_key=None, anthropic_key=None, gemini_key=None):
        """Permet √† l'utilisateur d'ajouter ses cl√©s API premium"""
        self.user_openai_key = openai_key
        self.user_anthropic_key = anthropic_key
        self.user_gemini_key = gemini_key
    
    def get_ai_response(self, agent_name, user_message, user_name=None, user_api_keys=None):
        """G√©n√®re une r√©ponse IA en utilisant la meilleure source disponible"""
        
        if agent_name not in self.agents_profiles:
            return "D√©sol√©, je ne reconnais pas cet agent."
        
        agent = self.agents_profiles[agent_name]
        
        # Mise √† jour des cl√©s utilisateur si fournies
        if user_api_keys:
            self.set_user_api_keys(**user_api_keys)
        
        # Construction du contexte
        system_prompt = agent['system_prompt']
        user_context = f"Utilisateur: {user_name or 'Utilisateur'}\nMessage: {user_message}\n\n{agent['name']}:"
        
        # üèÜ PRIORIT√â 1: APIs Premium Utilisateur
        response = self.try_premium_apis(system_prompt, user_context, agent_name)
        if response:
            return f"üî• {response}"
        
        # üåê PRIORIT√â 2: Hugging Face Gratuit
        response = self.try_huggingface_apis(system_prompt, user_context)
        if response:
            return f"ü§ñ {response}"
        
        # üè† PRIORIT√â 3: Ollama Local
        response = self.try_ollama_local(system_prompt, user_context)
        if response:
            return f"üñ•Ô∏è {response}"
        
        # üõ°Ô∏è FALLBACK: Intelligence Int√©gr√©e
        return self.get_intelligent_fallback(agent_name, user_message)
    
    def try_premium_apis(self, system_prompt, user_context, agent_name):
        """Essaie les APIs premium de l'utilisateur"""
        
        # OpenAI GPT
        if self.user_openai_key:
            try:
                openai.api_key = self.user_openai_key
                response = openai.ChatCompletion.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_context}
                    ],
                    max_tokens=250,
                    temperature=0.7
                )
                return response.choices[0].message.content.strip()
            except Exception as e:
                print(f"Erreur OpenAI: {e}")
        
        # Anthropic Claude
        if self.user_anthropic_key:
            try:
                client = anthropic.Anthropic(api_key=self.user_anthropic_key)
                response = client.messages.create(
                    model="claude-3-haiku-20240307",
                    max_tokens=250,
                    temperature=0.7,
                    system=system_prompt,
                    messages=[{"role": "user", "content": user_context}]
                )
                return response.content[0].text.strip()
            except Exception as e:
                print(f"Erreur Anthropic: {e}")
        
        return None
    
    def try_huggingface_apis(self, system_prompt, user_context):
        """Essaie les APIs Hugging Face gratuites"""
        
        headers = {"Content-Type": "application/json"}
        if self.hf_api_key:
            headers["Authorization"] = f"Bearer {self.hf_api_key}"
        
        # Prompt optimis√© pour Hugging Face
        hf_prompt = f"{system_prompt}\n\n{user_context}"
        
        payload = {
            "inputs": hf_prompt,
            "parameters": {
                "max_new_tokens": 200,
                "temperature": 0.7,
                "return_full_text": False
            }
        }
        
        for model_url in self.hf_models:
            try:
                response = requests.post(model_url, headers=headers, json=payload, timeout=15)
                
                if response.status_code == 200:
                    result = response.json()
                    if isinstance(result, list) and len(result) > 0:
                        text = result[0].get('generated_text', '').strip()
                        if text and len(text) > 20:  # R√©ponse valide
                            return self.clean_ai_response(text)
                    elif isinstance(result, dict):
                        text = result.get('generated_text', '').strip()
                        if text and len(text) > 20:
                            return self.clean_ai_response(text)
                        
            except Exception as e:
                print(f"Erreur HF {model_url}: {e}")
                continue
        
        return None
    
    def try_ollama_local(self, system_prompt, user_context):
        """Essaie Ollama en local"""
        
        for model in self.ollama_models:
            try:
                # Test si Ollama est disponible
                test_response = requests.get(f"{self.ollama_url}/api/tags", timeout=5)
                if test_response.status_code != 200:
                    continue
                
                # G√©n√©ration avec Ollama
                payload = {
                    "model": model,
                    "prompt": f"{system_prompt}\n\n{user_context}",
                    "stream": False,
                    "options": {
                        "temperature": 0.7,
                        "num_predict": 200
                    }
                }
                
                response = requests.post(
                    f"{self.ollama_url}/api/generate", 
                    json=payload, 
                    timeout=30
                )
                
                if response.status_code == 200:
                    result = response.json()
                    text = result.get('response', '').strip()
                    if text and len(text) > 20:
                        return self.clean_ai_response(text)
                        
            except Exception as e:
                print(f"Erreur Ollama {model}: {e}")
                continue
        
        return None
    
    def clean_ai_response(self, response):
        """Nettoie et optimise la r√©ponse IA"""
        if not response:
            return ""
        
        # Supprimer les pr√©fixes r√©p√©titifs
        prefixes_to_remove = ['Assistant:', 'AI:', 'Bot:', 'Agent:']
        for prefix in prefixes_to_remove:
            response = response.replace(prefix, '').strip()
        
        # Limiter la longueur
        if len(response) > 350:
            response = response[:350] + "..."
        
        return response
    
    def get_intelligent_fallback(self, agent_name, user_message):
        """Fallback intelligent int√©gr√©"""
        
        agent = self.agents_profiles[agent_name]
        message_lower = user_message.lower()
        
        # R√©ponses contextuelles par mots-cl√©s
        smart_responses = {
            'alex': {
                'email': "üìß Gmail optimis√© en 3 √©tapes : 1) Filtres automatiques par exp√©diteur/sujet, 2) Libell√©s color√©s par priorit√©, 3) R√®gle des 2 minutes. Configurons ensemble votre syst√®me personnalis√© ! Quel est votre plus gros probl√®me email actuellement ?",
                'productivit√©': "‚ö° Ma m√©thode triple efficacit√© : Planification matinale (15min) + Blocs de focus sans interruption (90min max) + R√©vision vesp√©rale (10min). Commen√ßons par identifier vos 3 priorit√©s du jour. Lesquelles sont-elles ?",
                'organisation': "üéØ Syst√®me GTD simplifi√© : Capturer tout dans un seul endroit ‚Üí Clarifier l'action suivante ‚Üí Organiser par contexte ‚Üí R√©viser hebdomadairement. Avez-vous un outil de capture fiable actuellement ?",
                'default': "üëã Alex Wave, expert productivit√© ! Je transforme le chaos quotidien en efficacit√© zen. Gmail, organisation, workflows... Quel est votre d√©fi num√©ro 1 aujourd'hui ?"
            },
            'lina': {
                'linkedin': "üîó LinkedIn strat√©gique : Profil magn√©tique (photo pro + titre accrocheur) + Contenu de valeur 3x/semaine + Engagement authentique quotidien. Sur quel pilier commencer ? Profil, contenu, ou networking ?",
                'networking': "üåü Networking authentique = Donner avant de recevoir ! Strat√©gie : 1) Identifier 5 personnes cl√©s, 2) Partager leur contenu avec commentaires, 3) Messages personnalis√©s de valeur. Votre secteur d'activit√© ?",
                'professionnel': "üíº Personal branding triptyque : Expertise (ce que vous savez faire) + R√©putation (ce qu'on dit de vous) + R√©seau (qui vous conna√Æt). Lequel d√©velopper en priorit√© absolue ?",
                'default': "üí´ Lina Wave ! Je transforme votre potentiel professionnel en opportunit√©s concr√®tes. LinkedIn, networking, influence... Quel est votre objectif de d√©veloppement professionnel ?"
            },
            'marco': {
                'social': "üì± Strat√©gie social media gagnante : 1 plateforme principale ma√Ætris√©e + Contenu pilier coh√©rent + Engagement r√©gulier authentique. Instagram, TikTok, LinkedIn ? Laquelle prioriser pour commencer ?",
                'contenu': "üé® Formule contenu engageant : Storytelling personnel + Valeur ajout√©e claire + √âmotion authentique + Call-to-action pr√©cis. Quel message unique voulez-vous porter au monde ?",
                'viral': "üöÄ Ingr√©dients viralit√© 2024 : Timing optimal + √âmotion forte + Facilit√© de partage + Pertinence culturelle. Mais l'engagement authentique bat la viralit√© ! Votre niche d'expertise ?",
                'default': "üé¨ Marco Wave ! Expert en contenu qui cartonne sur les r√©seaux. Je transforme vos id√©es en publications qui engagent vraiment. Quel d√©fi cr√©atif vous pr√©occupe ?"
            },
            'sofia': {
                'planning': "üìÖ Planification strat√©gique en pyramide : Vision annuelle ‚Üí Objectifs trimestriels ‚Üí Plans mensuels ‚Üí Actions hebdomadaires ‚Üí T√¢ches quotidiennes. Vos 3 grandes priorit√©s de ce mois ?",
                'organisation': "üìã Mon syst√®me d'organisation universel : Capture centralis√©e ‚Üí Clarification imm√©diate ‚Üí Cat√©gorisation logique ‚Üí Actions programm√©es ‚Üí R√©vision hebdomadaire. Quel maillon faible identifier ?",
                'calendrier': "‚è∞ Calendrier zen en 4 r√®gles : 1) Bloquer les priorit√©s AVANT tout, 2) Garder 25% de buffer impr√©vu, 3) Grouper les t√¢ches similaires, 4) R√©visions quotidiennes 10min. Votre d√©fi temporel principal ?",
                'default': "üóìÔ∏è Sofia Wave ! Je transforme le chaos en s√©r√©nit√© organis√©e. Planning, calendriers, syst√®mes... Quelle zone de votre vie m√©rite une organisation parfaite en premier ?"
            }
        }
        
        if agent_name in smart_responses:
            responses = smart_responses[agent_name]
            
            # Recherche de mot-cl√© pertinent
            for keyword, response in responses.items():
                if keyword != 'default' and keyword in message_lower:
                    return response
            
            return responses['default']
        
        return "üåä Je suis l√† pour vous aider ! Pouvez-vous pr√©ciser votre demande ?"

# Instance globale
universal_ai = UniversalAISystem()
